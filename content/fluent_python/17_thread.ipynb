{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了高效处理网络 I/O，需要使用并发，因为网络有很高的延时，为了不浪费 CPU 周期去等待，最好在收到网络相应之前做些其他的事\n",
    "\n",
    "我们首先看依次从网络下载的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 flags downloaded in 33.59s\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import time\n",
    "import sys\n",
    "\n",
    "import requests\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'\n",
    "DEST_DIR = 'downloads/'\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "        \n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "def show(text):\n",
    "    print(text, end=' ') # 输出末尾的换行符变成了空格\n",
    "    sys.stdout.flush() #Python 中正常情况下,遇到换行才会刷新 stdout 缓冲。所以这里手动刷新缓冲\n",
    "    \n",
    "def download_many(cc_list):\n",
    "    for cc in sorted(cc_list):\n",
    "        image = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "def main(download_many):\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "    \n",
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意上面代码细节，导入标准库 os time 和 sys 之后，使用一个空格分开了非标准库 requests\n",
    "\n",
    "为了清楚起见，这里并没有处理异常。看到依次下载需要 33 秒\n",
    "\n",
    "## 使用 concurrent.futures 模块下载\n",
    "\n",
    "concurrent.futures 模块的主要特色是 ThreadPoolExecutor 和 ProcessPoolExecutor 类，这两个类实现的接口能分别在不同的线程或进程中执行可调用的对象，这两个类在内部维护着一个工作线程或进程池，以及要执行的任务队列。不过这个接口抽象层级很高，像下国旗这种简单的案例，不用关心任何实现细节\n",
    "\n",
    "下面展示了如何使用 ThreadPoolExecutor.map 方法，以最简单的方式实现并发下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN FR EG ID RU TR BR IN CD NG JP PK PH MX US IR ET DE BD VN \n",
      "20 flags downloaded in 2.18s\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20 \n",
    "\n",
    "def download_one(cc):\n",
    "    image = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        # 与内置的 map 方法类似，不过 download_one 函数会在多个线程中并发调用\n",
    "        # map 方法返回一个生成器，因此可以迭代，获取各个函数的返回值\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    \n",
    "    return len(list(res))\n",
    "\n",
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里为了方便引用了第一个代码块的一些函数，注意，上面的 download_one 函数其实是第一个例子的 for 循环结构体，编写并发代码经常这样重构，把依次执行的 for 循环改成函数，以便并发调用\n",
    "\n",
    "## 期物在哪里\n",
    "\n",
    "期物是 concurrent.futures 模块和 asyncio 包的重要组件，可是，作为这两个库的用户，我们有时候却见不到期物，在上面例子背后用到了期物，但是我们编写的代码并没有直接使用。这一节概述期物并举一个例子，展示用法\n",
    "\n",
    "从 Python3.4 起，标准库中有两个名为 Future 的类：concurrent.futures.Future 和 asyncio.Future。这两个类的作用完全相同：两个 Future 类的实例都表示可能已经完成或者尚未完成的延时计算。这与 Twisted 引擎中的 Deferred 类，Tornado 框架中的 Future 类，以及多个 JavaScript 库中的 Promise 对象类似\n",
    "\n",
    "期物封装待完成的操作，可以放入队列，完成的状态可以查询，得到结果（或抛出异常）后可以获取结果（或异常）。\n",
    "\n",
    "我们要记住一件事：通常情况自己不应该创建期物，而只能由并发框架（concurrent.futures 或 asyncio）实例化。原因很简单：期物表示终将发生的事，而确定某件事会发生的唯一方式是执行的时间已经排定。因此，只有排定把某件事交给 concurrent.futures.Executor 子类处理，才会创建 concurrent.futures.Future 实例。例如 Executor.submit() 方法的参数是一个可调用的对象，调用这个方法后会为传入的可调用对象排期，并返回一个期物。\n",
    "\n",
    "客户端代码不应该改变期物的状态，并发框架在期物表示的延时计算结束后会改变期物状态，而我们无法控制计算何时结束\n",
    "\n",
    "这两种期物都有 .done() 方法，这个方法不阻塞，返回值是 布尔值，指明期物链接的可调用对象是否已经执行。客户端代码通常不会询问期物是否运行结束，而会等待通知。因此，两个 Future 类都用 .add_done_callback() 方法；这个方法只有一个参数，类型是可调用的对象，期物运行结束后会调用指定的可调用对象\n",
    "\n",
    "此外，还有 .result() 方法，在期物运行结束后调用的话，这个方法在两个 Future 类中的作用相同；返回可调用对象的结果，或者重新抛出执行的可调用的对象时抛出异常。可是，如果期物没有运行结束，result 方法在两个 Future 类中的行为相差很大。对 concurrency.futures.Future 实例来说，调用 f.result() 方法会阻塞调用方所在的线程，直到有结果可返回，此时， result 方法可以接收可选的 timeout 参数，如果在指定时间期物没有完毕，会抛出 TimeError 异常，第 18 章你会发现，asyncio.Future.result 方法不支持设定超时时间，在那个库中获取期物的结果最好使用 yield from 结构。不过，对 concurrency.futures.Future 实例不能这么做。\n",
    "\n",
    "这两个库都有几个函数返回期物，其他函数则使用期物，以用户易于理解的方式实现自身，上面的例子中的 Executor.map 方法属于后者：返回值是一个迭代器，迭代器的 `__next__` 方法调用各个期物的 result 方法，因此我们得到的是各个期物的结果，而非期物本身\n",
    "\n",
    "为了从实用的角度理解期物，我们使用 concurrent.futures.as_complete 函数重写上面例子，这个函数是一个期物列表，返回值是一个迭代器，在期物运行结束后产出期物\n",
    "\n",
    "为了使用 futures.as_completed 函数,只需修改 download_many 函数,把较抽象的 executor.map 调用换成两个 for 循环:一个用于创建并排定期物,另一个用于获取期物的结果。同时,我们会添加几个print 调用,显示运行结束前后的期物。修改后的 download_many 函数如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR: <Future at 0x7f174c4bbcc0 state=running>\n",
      "Scheduled for CN: <Future at 0x7f174c4bf630 state=running>\n",
      "Scheduled for ID: <Future at 0x7f174c4b3dd8 state=running>\n",
      "Scheduled for IN: <Future at 0x7f174c4b74e0 state=pending>\n",
      "Scheduled for US: <Future at 0x7f174c4b7128 state=pending>\n",
      "BR <Future at 0x7f174c4bbcc0 state=finished returned str> result: 'BR'\n",
      "ID <Future at 0x7f174c4b3dd8 state=finished returned str> result: 'ID'\n",
      "IN <Future at 0x7f174c4b74e0 state=finished returned str> result: 'IN'\n",
      "US <Future at 0x7f174c4b7128 state=finished returned str> result: 'US'\n",
      "CN <Future at 0x7f174c4bf630 state=finished returned str> result: 'CN'\n",
      "\n",
      "5 flags downloaded in 4.58s\n"
     ]
    }
   ],
   "source": [
    "def download_many(cc_list):\n",
    "    cc_list = cc_list[:5]\n",
    "    \n",
    "    # max_workers 硬编码为 3，以便在输出中观察待完成的期物\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        to_do = []\n",
    "        # 按照字母表迭代国家代码，明确表明输出的顺序与输入一致\n",
    "        for cc in sorted(cc_list):\n",
    "            # submit 方法可以排定调用对象的执行时间，然后返回一个期物，表示这个待执行的操作\n",
    "            future = executor.submit(download_one, cc)\n",
    "            to_do.append(future)\n",
    "            msg = 'Scheduled for {}: {}'\n",
    "            print(msg.format(cc, future))\n",
    "        \n",
    "        results = []\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "            msg = '{} result: {!r}'\n",
    "            print(msg.format(future, res))\n",
    "            results.append(res)\n",
    "        return len(results)\n",
    "    \n",
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这个示例中调用 future.result() 方法绝不会阻塞，因为 future 由 as_completed 函数产出。\n",
    "\n",
    "上面输出可以看出，期物的 repr() 方法会显示期物的状态；前 3 个期物是 running，因为有 3 个工作的线程\n",
    "\n",
    "后两个期物的状态是 pending，等待有线程可用\n",
    "\n",
    "严格的来说，我们现在的脚本都不能并行下载，因为 GIL 锁的限制，他们都在单个线程中运行\n",
    "\n",
    "## 阻塞型 Ｉ/O 和 GIL\n",
    "\n",
    "CPython 解释器本身就不是线程安全的，因此有全局解释器锁（GIL），一次只允许使用一个线程执行 Python 字节码。因此，一个 Python 进程通常不能使用多个 CPU 核心\n",
    "\n",
    "> 这是 CPython 解释器的局限，与 Python 语言无关，Jython 和 IronPython 没有这种限制，不过目前最快的 PyPy 也有 GIL\n",
    "\n",
    "不过标准库中的阻塞型 I/O 操作函数在操作系统返回结果时都会释放 GIL，这意味着一个内置的函数或一个使用 C 语言编写的扩展释放 GIL。其实有个使用 C 语言编写的 Python 库可以管理 GIL，不过太麻烦，不建议使用\n",
    "\n",
    "然而，标准库中所有执行阻塞型 I/O 操作的函数，在等待操作系统返回结果时都会释放 GIL。这意味着 Python 在这个层次可以使用多线程程，I/O 密集型 Python 程序能从中收益，一个 Python 程序等待网络响应，阻塞型 I/O 函数会释放 GIL，再运行一个进程\n",
    "\n",
    "> Python 标准库中所有的阻塞型 I/O 函数都会释放 GIL，允许其他线程运行。time.sleep() 函数也会释放 GIL。因此，尽管有 GIL，Python 还是能在 I/O 密集型应用发挥作用\n",
    "\n",
    "## 使用 concurrent.futures 模块启动进程\n",
    "\n",
    "concurrent.futures 模块文档副标题是执行并行任务。这个模块实现的是真正的并行计算，因为它使用 ProcessPoolExecutor 类把工作分配给多个进程处理，因此，如果需要做 CPU 密集型处理，使用这个模块能绕开 GIL，利用所有 CPU 核心\n",
    "\n",
    "ProcessPoolExecutor 和 ThreadPoolExecutor 类都实现了通用的Executor 接口,因此使用 concurrent.futures 模块能特别轻松地把基于线程的方案转成基于进程的方案。\n",
    "\n",
    "只需要把第二个例子的 \n",
    "\n",
    "```\n",
    "def download_many(cc_list):\n",
    "     workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "```\n",
    "改成：\n",
    "```\n",
    "def download_many(cc_list):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN BD BR ET CD EG ID FR IN JP IR DE NG MX RU PH VN PK TR US \n",
      "20 flags downloaded in 4.89s\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20 \n",
    "\n",
    "def download_one(cc):\n",
    "    image = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    \n",
    "    return len(list(res))\n",
    "\n",
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于简单用途来说，这两个实现 Executor 接口的唯一指的注意的区别是，`ThreadPoolExecutor.__init__` 方法需要 max_workers 参数，指定线程池中的线程数量，在 ProcessPoolExecutor 类中，那个参数是可选的，大多数时候不适用，默认值是 os.cpu_count() 函数返回的 CPU 数量，这样处理说得通，因为对 CPU 密集型的处理来说，不可能要求使用超过 CPU 数量的职程。二队 I/O 密集型处理来说，可以在一个 ThreadPoolExecutor 实例中使用 10 和 100 个或 1000 个线程，最佳线程数量取决于线程做的事，以及可用内存等\n",
    "\n",
    "## 实验 Executor.map 方法\n",
    "\n",
    "如果想并发运行多个可调用对象，最简单方式是使用上面 Executor.map 方法，下面展示了这个方法的某些运作细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:43:36] Script starting\n",
      "[14:43:36] loiter(0): doing nothing for 0s...[14:43:36] \n",
      "[14:43:36][14:43:36]\tloiter(1): doing nothing for 1s...[14:43:36] \n",
      " \t\tloiter(2): doing nothing for 2s... results:loiter(0): done\n",
      " \n",
      "<generator object Executor.map.<locals>.result_iterator at 0x7f174c457eb8>[14:43:36]\n",
      " [14:43:36]\t\t\tloiter(3): doing nothing for 3s... \n",
      "Waiting for individual results:\n",
      "[14:43:36] result 0: 0\n",
      "[14:43:37] \tloiter(1): done\n",
      "[14:43:37] \t\t\t\tloiter(4): doing nothing for 4s...\n",
      "[14:43:37] result 1: 10\n",
      "[14:43:38] [14:43:38]\t\tloiter(2): done \n",
      "result 2: 20\n",
      "[14:43:39] \t\t\tloiter(3): done\n",
      "[14:43:39] result 3: 30\n",
      "[14:43:41] \t\t\t\tloiter(4): done\n",
      "[14:43:41] result 4: 40\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "# 将参数打印，前面加上时间戳\n",
    "def display(*args):\n",
    "    print(strftime('[%H:%M:%S]'), end=' ')\n",
    "    print(*args)\n",
    "\n",
    "# 开始时候显示一个消息，休眠 n 秒，休眠 n 秒，结束时候显示一个消息\n",
    "# 消息使用制表符缩进，缩进量由 n 确定\n",
    "def loiter(n):\n",
    "    msg = '{}loiter({}): doing nothing for {}s...'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n * 10\n",
    "\n",
    "def main():\n",
    "    display('Script starting')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3)\n",
    "    results = executor.map(loiter, range(5))\n",
    "    display('results:', results)\n",
    "    display('Waiting for individual results:')\n",
    "    # for 循环中的 enumerate 函数会隐式调用 next(results),\n",
    "    # 这个函数又会在(内部)表示第一个任务(loiter(0))的 _f 期物上调用_f.result() 方法。\n",
    "    # result 方法会阻塞,直到期物运行结束,因此这个循环每次迭代时都要等待下一个结果做好准备。\n",
    "    for i, result in enumerate(results):\n",
    "        display('result {}: {}'.format(i, result))\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executor.map 函数易于使用,不过有个特性可能有用,也可能没用,具体情况取决于需求:这个函数返回结果的顺序与调用开始的顺序一\n",
    "致。如果第一个调用生成结果用时 10 秒,而其他调用只用 1 秒,代码会阻塞 10 秒,获取 map 方法返回的生成器产出的第一个结果。在此之\n",
    "后,获取后续结果时不会阻塞,因为后续的调用已经结束。如果必须等到获取所有结果后再处理,这种行为没问题;不过,通常更可取的方式\n",
    "是,不管提交的顺序,只要有结果就获取。为此,要把Executor.submit 方法和 futures.as_completed 函数结合起来使\n",
    "用。\n",
    "\n",
    "> executor.submit 和 futures.as_completed 这个组合比executor.map 更灵活,因为 submit 方法能处理不同的可调用对象和参数,而executor.map 只能处理参数不同的同一个可调用对象。此外,传给futures.as_completed 函数的期物集合可以来自多个 Executor 实例,例如一些由 ThreadPoolExecutor 实例创建,另一些由 ProcessPoolExecutor 实例创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
